Available lexical databases
===========================

This is a directory of open lexical databases for the [openlexicon
project](http://chrplr.github.io/openlexicon). Clicking on the name of a
database will provide more information.

Most databases can explored on-line at
<http://www.lexique.org/shiny/openlexique> (Select the base in dataset),
or downloaded from <http://www.lexique.org/databases>

Warning: Do not edit this document directly; Its sources is at
<http://github.com/chrplr/openlexicon/databases-docs>.

<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->
**Table of Contents**

-   [Français](#français)
-   [English (American and British)](#english-american-and-british)
-   [Chinese](#chinese)
-   [Multilingual](#multilingual)

-   [Usage](#usage)

<!-- markdown-toc end -->
Français
--------

  ------------------------------------------------------------------------------------------------------------------------------------------------------
  Base                                                                                        Description
  ------------------------------------------------------------------------------------------- ----------------------------------------------------------
  [Lexique3](Lexique382/README-Lexique.md)                                                    *Lexique3* est une base de données lexicales du français
                                                                                              qui fournit pour \~140000 mots du français: les
                                                                                              représentations orthographiques et phonémiques, les lemmes
                                                                                              associés, la syllabation, la catégorie grammaticale, le
                                                                                              genre et le nombre, les fréquences dans un corpus de
                                                                                              livres et dans un corpus de sous-titres de filems, etc.

  [Anagrammes](anagrammes/README-anagrammes.md)                                               *Anagrammes* liste plus de 25000 ensembles d'anagrammes du
                                                                                              français.

  [Voisins](Voisins/README-Voisins.md)                                                        *Voisins* liste les voisins orthographiques par
                                                                                              substitution d'une lettre pour 130000 mots français.

  [French Lexicon Project](FrenchLexiconProject/README-FrenchLexiconProject.md)               The *French Lexicon Project* (FLP) was inspired from the
                                                                                              *English Lexicon Project* (Balota et al. 2007). It
                                                                                              provides visual lexical decision time for about 39000
                                                                                              French words and as many pseudowords. The full data
                                                                                              represents 1942000 reactions times from 975 participants.

  [Megalex](Megalex/README-Megalex.md)                                                        *Megalex* provides visual and auditory lexical decision
                                                                                              times and accuracy rates several thousands of words:
                                                                                              Visual lexical decision data are available for 28466
                                                                                              French words and the same number of pseudowords, and
                                                                                              auditory lexical decision data are available for 17876
                                                                                              French words and the same number of pseudowords.

  [Chronolex](Chronolex/README-Chronolex.md)                                                  *Chronolex* provides naming times, lexical decision times
                                                                                              and progressive demasking scores on most monosyllabic
                                                                                              monomorphemic French (about 1500 items). Thirty-seven
                                                                                              participants were tested in the naming task, 35
                                                                                              additionnal participants in the lexical decision task and
                                                                                              33 additionnal participants were tested in the progressive
                                                                                              demasking task.

  [Brulex](Brulex/README-Brulex.md)                                                           *Brulex* donne, pour environ 36.000 mots de la langue
                                                                                              française, l'orthographe, la prononciation, la classe
                                                                                              grammaticale, le genre, le nombre et la fréquence d'usage.
                                                                                              Il contient également d'autres informations utiles à la
                                                                                              sélection de matériel expérimental (notamment, point
                                                                                              d'unicité, comptage des voisins lexicaux, patrons
                                                                                              phonologiques, fréquence moyenne des digrammes).

  [Gougenheim100](Gougenheim100/README-Gougenheim.md)                                         *Gougenheim100* présente, pour 1064 mots, leur fréquence
                                                                                              et leur répartition (nombre de textes dans lesquels ils
                                                                                              apparaissent). Le corpus sur lequel, il est basé est un
                                                                                              corpus de langue oral basé sur un ensembles d'entretiens
                                                                                              avec 275 personnes. C'est donc non seulement un corpus de
                                                                                              langue orale mais aussi de langue produite. Le corpus
                                                                                              original comprend 163 textes, 312.135 mots et 7.995 lemmes
                                                                                              différents.

  [Chacqfam](chacqfam/README-Chacqfam.md)                                                     CHACQFAM est une base de données renseignant l'âge
                                                                                              d'acquisition estimé et la familiarité de 1225 mots
                                                                                              Français

  [Frantext](Frantext/README-Frantext.md)                                                     *Frantext* fournit la liste de tous les types
                                                                                              orthographiques obtenus après tokenization du sous-corpus
                                                                                              de Frantext utilisé pour calculer les fréquences
                                                                                              "livres"\" de Lexique.

  [francais-GUTenberg](Liste-de-mots-francais-Gutenberg/README-liste-francais-Gutenberg.md)   Liste de 336531 mots français obtenue à partir du
                                                                                              dictionnaire ispell Français-GUTenberg

  [Fr- Familiary660](Robert-Dorot-Mathey/README-RobertDorotMathey2012.md)                     Familiarités de 660 mots estimées par des adultes jeunes
                                                                                              et des adultes âgés.
  ------------------------------------------------------------------------------------------------------------------------------------------------------

English (American and British)
------------------------------

  -------------------------------------------------------------------------------
  Base                                                           Description
  -------------------------------------------------------------- ----------------
  [SUBTLEX-US](SUBTLEX-US/README-SUBTLEXus.md)                   *SUBTLEXus*
                                                                 (Brysbaert, New
                                                                 & Keuleers,
                                                                 2012) provides
                                                                 two frequency
                                                                 measures based
                                                                 on American
                                                                 movies subtitles
                                                                 (51 million
                                                                 words in total):
                                                                 a) The frequency
                                                                 per million
                                                                 words, called
                                                                 SUBTLEXWF (word
                                                                 form frequency)
                                                                 b) The
                                                                 percentage of
                                                                 films in which a
                                                                 word occurs,
                                                                 called SUBTLEXCD
                                                                 (contextual
                                                                 diversity)

  [British Lexicon                                               The British
  Project](BritishLexiconProject/README-BritishLexiconProject)   Lexicon Project
                                                                 (Keuleers et al,
                                                                 2012) contains
                                                                 lexical decision
                                                                 data for over
                                                                 28,000
                                                                 monosyllabic and
                                                                 disyllabic
                                                                 English words..

  [English Lexicon Project](EnglishLexiconProject/README-ELP.md) The English
                                                                 Lexicon Project
                                                                 provides a
                                                                 standardized
                                                                 behavioral and
                                                                 descriptive data
                                                                 set for 40,481
                                                                 words and 40,481
                                                                 nonwords. Data
                                                                 from 816
                                                                 participants
                                                                 across six
                                                                 universities
                                                                 were collected
                                                                 in a lexical
                                                                 decision task
                                                                 (approximately
                                                                 3400 responses
                                                                 per
                                                                 participant),
                                                                 and data from
                                                                 444 participants
                                                                 were collected
                                                                 in a speeded
                                                                 naming task
                                                                 (approximately
                                                                 2500 responses
                                                                 per participant)
  -------------------------------------------------------------------------------

Chinese
-------

  --------------------------------------------------------------------------------------------------------
  Base                                            Description
  ----------------------------------------------- --------------------------------------------------------
  [SUBTLEX-CH](SUBTLEX-CH/README-subtlex-ch.md)   *SUBTLEX-CH* (Cai & Brysbaert 2010) is a database of
                                                  Chinese word and character frequencies based on a corpus
                                                  of film and television subtitles (46.8 million
                                                  characters, 33.5 million words).

  --------------------------------------------------------------------------------------------------------

Multilingual
------------

  ------------------------------------------------------------------------------------------
  Base                                      Description
  ----------------------------------------- ------------------------------------------------
  [WorldLex](WorldLex/README-Worldlex.md)   Worldlex provides word frequencies estimated
                                            from web pages collected in 66 languages.

  ------------------------------------------------------------------------------------------

------------------------------------------------------------------------

Usage
-----

**Accessing the content**

-   Many of these tables can explored at
    <http://www.lexique.org/shiny/openlexique>

-   They can be downloaded from <http://lexique.org/databases.zip>
    (Warning this file is over 100MB).

-   Most databases are provided in form of `.tsv` or `.csv` files
    (tab-separated-values or comma-separated-values). These are plain
    text files which can be easily imported in to R, MATLAB or Python,
    or even [opened with
    Excel](https://rievent.zendesk.com/hc/en-us/articles/360000029172-FAQ-How-do-I-open-a-tsv-file-in-Excel-).
    Check out our [script examples](../scripts/README.md).

**Similar lists or resources**

-   Marc Brysbaert's web site at <http://crr.ugent.be/programs-data>

**Crediting**

-   Most databases have associated publications listed in their
    respective \`README\*\* files. They must be cited in any derivative
    work!

**Contributing**\*

-   If you want to contribute, by adding a database, or just sending
    some corrections, please contact <christophe@pallier.org> and
    <boris.new@gmail.com>

------------------------------------------------------------------------

Back to [main page](../README.md)

------------------------------------------------------------------------

Time-stamp: \<2019-04-07 19:59:58 christophe\@pallier.org\>
